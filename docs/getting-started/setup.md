---
sidebar_position: 1
---

# ç’°å¢ƒè¨­å®š

åœ¨é–‹å§‹è¨“ç·´ AI æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘å€‘éœ€è¦å…ˆå»ºç«‹é©åˆçš„é–‹ç™¼ç’°å¢ƒã€‚æœ¬æŒ‡å—å°‡å¹«åŠ©ä½ é¸æ“‡åˆé©çš„å¹³å°ä¸¦å®Œæˆåˆå§‹è¨­å®šã€‚

## ğŸ–¥ï¸ é¸æ“‡è¨“ç·´å¹³å°

ä½ å¯ä»¥æ ¹æ“šè‡ªå·±çš„è³‡æºå’Œéœ€æ±‚é¸æ“‡ä»¥ä¸‹ä»»ä¸€å¹³å°ï¼š

### é¸é … 1ï¼šGoogle Colabï¼ˆæ¨è–¦æ–°æ‰‹ï¼‰

**å„ªé»ï¼š**
- âœ… å®Œå…¨å…è²»ï¼ˆæœ‰é™åˆ¶ï¼‰
- âœ… ç„¡éœ€æœ¬åœ°ç¡¬é«”
- âœ… é è£å¸¸ç”¨å¥—ä»¶
- âœ… å¯å‡ç´šåˆ° Colab Pro ç²å¾—æ›´å¥½çš„è³‡æº

**ç¼ºé»ï¼š**
- âŒ æ¯æ¬¡åŸ·è¡Œæ™‚é–“æœ‰é™åˆ¶
- âŒ éœ€è¦ç¶²è·¯é€£ç·š
- âŒ å…è²»ç‰ˆ GPU è³‡æºæœ‰é™

**é©åˆå°è±¡ï¼š** åˆå­¸è€…ã€é ç®—æœ‰é™ã€æƒ³å¿«é€Ÿé–‹å§‹

### é¸é … 2ï¼šæœ¬åœ° GPU

**å„ªé»ï¼š**
- âœ… ç„¡ä½¿ç”¨æ™‚é–“é™åˆ¶
- âœ… å¯é›¢ç·šå·¥ä½œ
- âœ… æ›´å¥½çš„éš±ç§ä¿è­·
- âœ… å¯è‡ªç”±å®‰è£å¥—ä»¶

**ç¼ºé»ï¼š**
- âŒ éœ€è¦æŠ•è³‡ç¡¬é«”
- âŒ éœ€è¦è‡ªè¡Œè¨­å®šç’°å¢ƒ
- âŒ é›»è²»æˆæœ¬

**æœ€ä½å»ºè­°é…ç½®ï¼š**
- GPUï¼šNVIDIA RTX 3060ï¼ˆ12GB VRAMï¼‰æˆ–ä»¥ä¸Š
- RAMï¼š16GB æˆ–ä»¥ä¸Š
- ç¡¬ç¢Ÿç©ºé–“ï¼š100GB å¯ç”¨ç©ºé–“

**é©åˆå°è±¡ï¼š** æœ‰é ç®—ã€éœ€è¦é•·æ™‚é–“è¨“ç·´ã€é‡è¦–éš±ç§

### é¸é … 3ï¼šé›²ç«¯æœå‹™ï¼ˆAWSã€GCPã€Azureï¼‰

**å„ªé»ï¼š**
- âœ… å½ˆæ€§æ“´å……è³‡æº
- âœ… å°ˆæ¥­ç´šç¡¬é«”
- âœ… æŒ‰éœ€ä»˜è²»

**ç¼ºé»ï¼š**
- âŒ éœ€è¦ä»˜è²»
- âŒ è¨­å®šç›¸å°è¤‡é›œ
- âŒ éœ€è¦ç®¡ç†æˆæœ¬

**é©åˆå°è±¡ï¼š** ä¼æ¥­ä½¿ç”¨ã€å¤§è¦æ¨¡è¨“ç·´ã€å°ˆæ¥­é–‹ç™¼

## ğŸš€ Google Colab å¿«é€Ÿè¨­å®š

### æ­¥é©Ÿ 1ï¼šé–‹å•Ÿ Colab

1. å‰å¾€ [Google Colab](https://colab.research.google.com/)
2. ä½¿ç”¨ Google å¸³è™Ÿç™»å…¥
3. é»é¸ã€Œæ–°å¢ç­†è¨˜æœ¬ã€

### æ­¥é©Ÿ 2ï¼šå•Ÿç”¨ GPU

1. é»é¸ä¸Šæ–¹é¸å–®ï¼š**åŸ·è¡Œéšæ®µ** â†’ **è®Šæ›´åŸ·è¡Œéšæ®µé¡å‹**
2. åœ¨ã€Œç¡¬é«”åŠ é€Ÿå™¨ã€é¸å–®ä¸­é¸æ“‡ **GPU** æˆ– **TPU**
3. é»é¸ã€Œå„²å­˜ã€

### æ­¥é©Ÿ 3ï¼šé©—è­‰ GPU å¯ç”¨æ€§

åœ¨ Colab ç­†è¨˜æœ¬ä¸­åŸ·è¡Œä»¥ä¸‹ç¨‹å¼ç¢¼ï¼š

```python
import torch

# æª¢æŸ¥ CUDA æ˜¯å¦å¯ç”¨
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

# å¦‚æœå¯ç”¨ï¼Œé¡¯ç¤º GPU è³‡è¨Š
if torch.cuda.is_available():
    print(f"GPU å‹è™Ÿ: {torch.cuda.get_device_name(0)}")
    print(f"GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
```

### æ­¥é©Ÿ 4ï¼šå®‰è£å¿…è¦å¥—ä»¶

```python
# å®‰è£ transformers å’Œç›¸é—œå¥—ä»¶
!pip install -q transformers datasets accelerate peft bitsandbytes

# é©—è­‰å®‰è£
import transformers
print(f"Transformers ç‰ˆæœ¬: {transformers.__version__}")
```

## ğŸ–¥ï¸ æœ¬åœ°ç’°å¢ƒè¨­å®š

### å‰ç½®éœ€æ±‚

1. **å®‰è£ Python 3.10+**
   - ä¸‹è¼‰ï¼šhttps://www.python.org/downloads/
   - å»ºè­°ä½¿ç”¨ Anacondaï¼šhttps://www.anaconda.com/

2. **å®‰è£ CUDA Toolkit**ï¼ˆNVIDIA GPU ä½¿ç”¨è€…ï¼‰
   - ä¸‹è¼‰ï¼šhttps://developer.nvidia.com/cuda-downloads
   - ç¢ºèªç‰ˆæœ¬ç›¸å®¹æ€§ï¼šhttps://pytorch.org/get-started/locally/

### å»ºç«‹è™›æ“¬ç’°å¢ƒ

```bash
# ä½¿ç”¨ conda
conda create -n ai-training python=3.10
conda activate ai-training

# æˆ–ä½¿ç”¨ venv
python -m venv ai-training
source ai-training/bin/activate  # Linux/Mac
# æˆ–
ai-training\Scripts\activate  # Windows
```

### å®‰è£ PyTorch

è¨ªå• [PyTorch å®˜ç¶²](https://pytorch.org/get-started/locally/) é¸æ“‡é©åˆä½ ç³»çµ±çš„ç‰ˆæœ¬ã€‚

```bash
# CUDA 11.8 ç¯„ä¾‹
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio
```

### é©—è­‰ PyTorch å®‰è£

```python
import torch

print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPU å‹è™Ÿ: {torch.cuda.get_device_name(0)}")
```

### å®‰è£å¿…è¦å¥—ä»¶

```bash
pip install transformers datasets accelerate peft bitsandbytes
pip install sentencepiece protobuf
pip install jupyter notebook  # å¯é¸ï¼šå¦‚æœæƒ³ä½¿ç”¨ Jupyter
```

## ğŸ“¦ å¥—ä»¶èªªæ˜

- **transformers**: Hugging Face çš„æ¨¡å‹åº«
- **datasets**: è³‡æ–™é›†è¼‰å…¥å’Œè™•ç†
- **accelerate**: åˆ†æ•£å¼è¨“ç·´å’Œæ··åˆç²¾åº¦
- **peft**: Parameter-Efficient Fine-Tuningï¼ˆå¦‚ LoRAï¼‰
- **bitsandbytes**: é‡åŒ–å’Œè¨˜æ†¶é«”å„ªåŒ–

## âœ… é©—è­‰è¨­å®š

å»ºç«‹æ¸¬è©¦è…³æœ¬ `test_setup.py`ï¼š

```python
import torch
import transformers
from transformers import AutoTokenizer, AutoModel

print("=== ç’°å¢ƒæª¢æŸ¥ ===")
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"Transformers: {transformers.__version__}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

print("\n=== æ¸¬è©¦æ¨¡å‹è¼‰å…¥ ===")
try:
    tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
    model = AutoModel.from_pretrained("bert-base-chinese")
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")

print("\nç’°å¢ƒè¨­å®šå®Œæˆï¼")
```

åŸ·è¡Œæ¸¬è©¦ï¼š

```bash
python test_setup.py
```

## ğŸ”§ å¸¸è¦‹å•é¡Œ

### CUDA ç„¡æ³•ä½¿ç”¨

1. ç¢ºèª NVIDIA é©…å‹•ç¨‹å¼å·²å®‰è£
2. æª¢æŸ¥ CUDA ç‰ˆæœ¬èˆ‡ PyTorch ç‰ˆæœ¬ç›¸å®¹æ€§
3. é‡æ–°å®‰è£å°æ‡‰ç‰ˆæœ¬çš„ PyTorch

### è¨˜æ†¶é«”ä¸è¶³

1. æ¸›å°‘æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰
2. ä½¿ç”¨æ¢¯åº¦ç´¯ç©
3. å•Ÿç”¨æ··åˆç²¾åº¦è¨“ç·´
4. ä½¿ç”¨é‡åŒ–ï¼ˆquantizationï¼‰

### å¥—ä»¶å®‰è£å¤±æ•—

1. ç¢ºèª Python ç‰ˆæœ¬æ­£ç¢º
2. æ›´æ–° pipï¼š`pip install --upgrade pip`
3. ä½¿ç”¨æ¸…è¯é¡åƒï¼ˆä¸­åœ‹åœ°å€ï¼‰ï¼š
   ```bash
   pip install -i https://pypi.tuna.tsinghua.edu.cn/simple <package-name>
   ```

## ä¸‹ä¸€æ­¥

ç’°å¢ƒè¨­å®šå®Œæˆå¾Œï¼Œæ¥ä¸‹ä¾†ï¼š

- ğŸ“– [äº†è§£åŸºç¤æ¦‚å¿µ](./concepts)
- ğŸ¤– [é¸æ“‡åˆé©çš„æ¨¡å‹](./model-selection)
- ğŸš€ [é–‹å§‹ç¬¬ä¸€å€‹å°ˆæ¡ˆ](./first-project)
