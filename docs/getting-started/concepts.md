---
sidebar_position: 2
---

# 基礎概念

在開始訓練 AI 模型之前，了解一些基本概念將幫助你更好地掌握整個流程。

## 🤖 什麼是 AI 模型訓練？

AI 模型訓練是讓電腦從資料中學習模式的過程。透過大量的範例資料，模型能夠學會如何處理類似的任務。

### 預訓練模型 vs. 從零訓練

- **預訓練模型**：已經在大量資料上訓練過的模型（如 GPT、BERT）
- **微調（Fine-tuning）**：在預訓練模型基礎上，使用特定領域資料進行進一步訓練
- **從零訓練**：完全從頭開始訓練模型（需要大量資源，本手冊不推薦）

:::tip 推薦做法
對於大多數應用場景，**微調預訓練模型**是最經濟有效的方法。
:::

## 🎯 什麼是微調（Fine-tuning）？

微調是在已有的預訓練模型基礎上，使用你的專業領域資料進行訓練，使模型適應特定任務。

### 微調的優勢

1. **節省資源**：不需要從零開始訓練
2. **效果更好**：利用預訓練模型的知識
3. **訓練更快**：所需資料量和時間都更少
4. **成本更低**：可在個人電腦或 Colab 上完成

### 微調類型

#### 全參數微調（Full Fine-tuning）
- 更新模型所有參數
- 效果最好但資源需求最高
- 適合有充足資源的場景

#### 參數高效微調（PEFT）
- 只更新少量參數
- 資源需求低
- 包含 LoRA、QLoRA、Adapter 等方法

## 📊 關鍵概念解釋

### 模型（Model）

模型是一個數學函數，接收輸入並產生輸出。在自然語言處理中：
- **輸入**：文字（如問題）
- **輸出**：文字（如答案）

### 參數（Parameters）

模型內部的可調整數值，決定模型的行為。參數數量越多，模型理論上越強大，但也需要更多資源。

常見模型規模：
- 小型：< 1B（十億）參數
- 中型：1B - 10B 參數
- 大型：10B - 100B 參數
- 超大型：> 100B 參數

### Token

文字處理的基本單位。一個 token 可能是：
- 一個完整的詞
- 一個字
- 一個詞的部分

**中文範例：**
- "我愛人工智慧" 可能被分成：["我", "愛", "人工", "智慧"]
- 大約 1 個中文字 = 1-2 個 tokens

### 訓練資料集

訓練模型所使用的資料，通常包含：
- **輸入範例**：問題、指令或上下文
- **期望輸出**：正確答案或回應

### 批次大小（Batch Size）

每次訓練迭代使用的資料筆數。
- 較大批次：訓練更穩定，但需要更多記憶體
- 較小批次：記憶體需求低，但可能不穩定

### 學習率（Learning Rate）

控制模型參數更新的幅度。
- 太高：訓練不穩定
- 太低：訓練太慢
- 典型值：1e-5 到 1e-3

### Epoch

完整遍歷一次訓練資料集稱為一個 epoch。
- 更多 epochs：模型有更多機會學習
- 太多 epochs：可能過擬合

### 過擬合（Overfitting）

模型過度學習訓練資料，導致在新資料上表現不佳。

**預防方法：**
- 使用更多訓練資料
- 早停（Early Stopping）
- Dropout
- 資料增強

## 🔧 LoRA 和 QLoRA

### LoRA（Low-Rank Adaptation）

一種參數高效微調方法，只訓練少量額外參數。

**優點：**
- 記憶體需求低（可減少 90%）
- 訓練速度快
- 容易切換不同版本

**適用場景：**
- 資源有限
- 需要訓練多個版本
- 快速實驗

### QLoRA（Quantized LoRA）

結合量化技術的 LoRA，進一步減少記憶體使用。

**優點：**
- 記憶體需求極低
- 可在更小的 GPU 上訓練大模型
- 幾乎不損失效能

**適用場景：**
- GPU 記憶體非常有限（< 12GB）
- 想訓練大模型但資源有限

## 💾 量化（Quantization）

將模型的數值精度降低以節省記憶體。

### 精度類型

- **FP32**（全精度）：32 位元浮點數
- **FP16**（半精度）：16 位元浮點數
- **INT8**：8 位元整數
- **INT4**：4 位元整數

**記憶體節省範例（7B 模型）：**
- FP32：約 28GB
- FP16：約 14GB
- INT8：約 7GB
- INT4：約 3.5GB

## 🎓 評估指標

### Perplexity（困惑度）

衡量模型預測的不確定性，越低越好。

### Accuracy（準確度）

預測正確的比例，適合分類任務。

### Loss（損失）

模型預測與實際答案的差距，越低越好。

### BLEU / ROUGE

文字生成品質的評估指標。

## 🚀 訓練流程概覽

```
1. 準備資料
   ↓
2. 載入預訓練模型
   ↓
3. 設定訓練參數
   ↓
4. 開始訓練
   ↓
5. 監控訓練過程
   ↓
6. 評估模型
   ↓
7. 調整參數（如需要）
   ↓
8. 部署模型
```

## 📚 常用術語對照

| 英文術語 | 中文 | 說明 |
|---------|------|------|
| Fine-tuning | 微調 | 在預訓練模型上進一步訓練 |
| Inference | 推論 | 使用模型進行預測 |
| Checkpoint | 檢查點 | 訓練過程中儲存的模型狀態 |
| Gradient | 梯度 | 參數更新的方向和幅度 |
| Optimizer | 優化器 | 控制參數更新的演算法 |
| Tokenizer | 分詞器 | 將文字轉換為 tokens |
| Embedding | 嵌入 | 文字的數值表示 |
| Hyperparameter | 超參數 | 訓練設定（如學習率） |

## 🎯 選擇合適的方法

根據你的資源選擇訓練方法：

### GPU 記憶體 < 8GB
- ✅ QLoRA (4-bit)
- ✅ 小型模型全參數微調

### GPU 記憶體 8-16GB
- ✅ QLoRA (4-bit)
- ✅ LoRA
- ✅ 中型模型全參數微調

### GPU 記憶體 > 24GB
- ✅ 所有方法
- ✅ 大型模型全參數微調
- ✅ 多 GPU 訓練

### Google Colab 免費版
- ✅ QLoRA (4-bit)
- ✅ LoRA（小型模型）
- ⚠️ 需要注意執行時間限制

## 下一步

了解基礎概念後，接下來：

- 🤖 [選擇合適的模型](./model-selection)
- 📊 [準備訓練資料](../data-preparation/data-collection)
- 🚀 [開始第一個專案](./first-project)

## 參考資源

- [Hugging Face 文件](https://huggingface.co/docs)
- [LoRA 論文](https://arxiv.org/abs/2106.09685)
- [QLoRA 論文](https://arxiv.org/abs/2305.14314)
